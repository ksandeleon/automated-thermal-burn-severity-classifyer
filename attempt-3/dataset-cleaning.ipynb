{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0d64d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 9561\n",
      "Number of labels: 9561\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Count files in directories\n",
    "images_dir = r'../dataset/compiled-new/images'\n",
    "labels_dir = r'../dataset/compiled-new/labels'\n",
    "\n",
    "num_images = len([f for f in os.listdir(images_dir) if not f.startswith('.')])\n",
    "num_labels = len([f for f in os.listdir(labels_dir) if not f.startswith('.')])\n",
    "\n",
    "print(f\"Number of images: {num_images}\")\n",
    "print(f\"Number of labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4440d696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have corresponding label files.\n"
     ]
    }
   ],
   "source": [
    "# Check for images without corresponding label files\n",
    "missing_labels = []\n",
    "\n",
    "for img_file in os.listdir(images_dir):\n",
    "    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        label_file = base_name + '.txt'\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        if not os.path.isfile(label_path):\n",
    "            missing_labels.append(img_file)\n",
    "\n",
    "if missing_labels:\n",
    "    print(\"Images missing label files:\")\n",
    "    for img in missing_labels:\n",
    "        print(img)\n",
    "else:\n",
    "    print(\"All images have corresponding label files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0072b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All label files have corresponding images.\n"
     ]
    }
   ],
   "source": [
    "# Check for label files without corresponding image files\n",
    "missing_images = []\n",
    "\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file.lower().endswith('.txt'):\n",
    "        base_name = os.path.splitext(label_file)[0]\n",
    "        # Check for any image extension\n",
    "        has_image = any(\n",
    "            os.path.isfile(os.path.join(images_dir, base_name + ext))\n",
    "            for ext in ['.jpg', '.jpeg', '.png']\n",
    "        )\n",
    "        if not has_image:\n",
    "            missing_images.append(label_file)\n",
    "\n",
    "if missing_images:\n",
    "    print(\"Label files missing corresponding images:\")\n",
    "    for label in missing_images:\n",
    "        print(label)\n",
    "else:\n",
    "    print(\"All label files have corresponding images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5baaabb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 duplicate images and their labels.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "# Remove duplicate images and their labels\n",
    "def file_hash(filepath):\n",
    "    \"\"\"Compute MD5 hash of a file (read in chunks for large files).\"\"\"\n",
    "    hasher = hashlib.md5()\n",
    "    with open(filepath, 'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hasher.update(chunk)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "hashes = {}\n",
    "duplicates = []\n",
    "\n",
    "for img_file in os.listdir(images_dir):\n",
    "    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        h = file_hash(img_path)\n",
    "        if h in hashes:\n",
    "            # Duplicate found: delete image and its label\n",
    "            print(f\"Deleting duplicate image: {img_file}\")\n",
    "            os.remove(img_path)\n",
    "            # Delete corresponding label\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            label_file = base_name + '.txt'\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            if os.path.isfile(label_path):\n",
    "                print(f\"Deleting label: {label_file}\")\n",
    "                os.remove(label_path)\n",
    "            duplicates.append(img_file)\n",
    "        else:\n",
    "            hashes[h] = img_file\n",
    "\n",
    "print(f\"Deleted {len(duplicates)} duplicate images and their labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cbee937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No empty label files found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check for empty .txt label files\n",
    "empty_labels = []\n",
    "\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file.lower().endswith('.txt'):\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        if os.path.getsize(label_path) == 0:\n",
    "            empty_labels.append(label_file)\n",
    "\n",
    "if empty_labels:\n",
    "    print(\"Empty label files found:\")\n",
    "    for label in empty_labels:\n",
    "        print(label)\n",
    "else:\n",
    "    print(\"No empty label files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838282c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 corrupted images and their labels.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Remove corrupted images and their labels\n",
    "corrupted_images = []\n",
    "\n",
    "for img_file in os.listdir(images_dir):\n",
    "    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img.verify()\n",
    "        except Exception as e:\n",
    "            print(f\"Corrupted or unreadable image: {img_file} ({e})\")\n",
    "            os.remove(img_path)\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            label_file = base_name + '.txt'\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            if os.path.isfile(label_path):\n",
    "                print(f\"Deleting label: {label_file}\")\n",
    "                os.remove(label_path)\n",
    "            corrupted_images.append(img_file)\n",
    "\n",
    "print(f\"Deleted {len(corrupted_images)} corrupted images and their labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c33d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8943 blurry images.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def is_blurry(image_path, threshold=100):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return True\n",
    "    variance = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    return variance < threshold\n",
    "\n",
    "blurry_images = []\n",
    "for img_file in os.listdir(images_dir):\n",
    "    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        if is_blurry(img_path):\n",
    "            blurry_images.append(img_file)\n",
    "\n",
    "print(f\"Found {len(blurry_images)} blurry images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d8a61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 618 non-blurry images and their labels to ../dataset-allin/images and ../dataset-allin/labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "images_dir = r'../dataset/compiled-new/images'\n",
    "labels_dir = r'../dataset/compiled-new/labels'\n",
    "output_images_dir = r'../dataset-allin/images'\n",
    "output_labels_dir = r'../dataset-allin/labels'\n",
    "\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "def is_blurry(image_path, threshold=80):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return True\n",
    "    variance = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    return variance < threshold\n",
    "\n",
    "kept_count = 0\n",
    "for img_file in os.listdir(images_dir):\n",
    "    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        if not is_blurry(img_path, threshold=100):\n",
    "            # Copy image\n",
    "            shutil.copy2(img_path, os.path.join(output_images_dir, img_file))\n",
    "            # Copy label if exists\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            label_file = base_name + '.txt'\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            if os.path.isfile(label_path):\n",
    "                shutil.copy2(label_path, os.path.join(output_labels_dir, label_file))\n",
    "            kept_count += 1\n",
    "\n",
    "print(f\"Copied {kept_count} non-blurry images and their labels to {output_images_dir} and {output_labels_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e599d1",
   "metadata": {},
   "source": [
    "DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "731f136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 1221 images into class folders 0, 1, 2 under ../dataset-allin/sorted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "images_dir = r'../dataset-v2/kaggle-good/archive'\n",
    "labels_dir = r'../dataset-v2/kaggle-good/archive'\n",
    "output_base = r'../dataset-allin/sorted'\n",
    "\n",
    "# Make output folders for each class\n",
    "for class_id in ['0', '1', '2']:\n",
    "    os.makedirs(os.path.join(output_base, class_id), exist_ok=True)\n",
    "\n",
    "moved = 0\n",
    "for img_file in os.listdir(images_dir):\n",
    "    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        label_file = base_name + '.txt'\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        if os.path.isfile(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                line = f.readline().strip()\n",
    "                if line:\n",
    "                    class_id = line.split()[0]\n",
    "                    if class_id in ['0', '1', '2']:\n",
    "                        dest_dir = os.path.join(output_base, class_id)\n",
    "                        shutil.copy2(os.path.join(images_dir, img_file), os.path.join(dest_dir, img_file))\n",
    "                        moved += 1\n",
    "\n",
    "print(f\"Copied {moved} images into class folders 0, 1, 2 under {output_base}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e49f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 482 train, 103 val, 104 test images copied.\n",
      "Class 1: 547 train, 117 val, 118 test images copied.\n",
      "Class 2: 257 train, 55 val, 56 test images copied.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_dir = r'../dataset-allin/sorted'\n",
    "output_base = r'../dataset-allin/split'\n",
    "splits = ['train', 'val', 'test']\n",
    "split_ratio = [0.7, 0.15, 0.15]  # 70% train, 15% val, 15% test\n",
    "\n",
    "for split in splits:\n",
    "    for class_id in ['0', '1', '2']:\n",
    "        os.makedirs(os.path.join(output_base, split, class_id), exist_ok=True)\n",
    "\n",
    "for class_id in ['0', '1', '2']:\n",
    "    class_dir = os.path.join(base_dir, class_id)\n",
    "    images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    images = sorted(images)\n",
    "\n",
    "    train_imgs, temp_imgs = train_test_split(images, test_size=(1 - split_ratio[0]), random_state=42)\n",
    "    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n",
    "\n",
    "    for img in train_imgs:\n",
    "        shutil.copy2(os.path.join(class_dir, img), os.path.join(output_base, 'train', class_id, img))\n",
    "    for img in val_imgs:\n",
    "        shutil.copy2(os.path.join(class_dir, img), os.path.join(output_base, 'val', class_id, img))\n",
    "    for img in test_imgs:\n",
    "        shutil.copy2(os.path.join(class_dir, img), os.path.join(output_base, 'test', class_id, img))\n",
    "\n",
    "    print(f\"Class {class_id}: {len(train_imgs)} train, {len(val_imgs)} val, {len(test_imgs)} test images copied.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
